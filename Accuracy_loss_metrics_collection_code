# Copyright (C) 2020-2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

"""You may copy this file as the starting point of your own model."""

import logging
# I added
import os, json, time
from keras.optimizers import Adam
import tensorflow as tf

from keras.layers import Conv2D, Dense, Flatten
from keras.models import Sequential

from openfl.federated import KerasTaskRunner

logger = logging.getLogger(__name__)


    #added metrics class with functions to track accuracy/loss throughout rounds, writes data to file
class _MetricsCB(tf.keras.callbacks.Callback):
    def __init__(self, owner): self.o = owner
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        self.o._acc.append(float(logs.get("val_accuracy", 0.0)))
        self.o._loss.append(float(logs.get("val_loss", 0.0)))
    def on_train_end(self, logs=None):
        outdir = os.environ.get("OUTDIR", "artifacts")
        os.makedirs(outdir, exist_ok=True)
        with open(os.path.join(outdir, "metrics_raw.json"), "w") as f:
            json.dump({
                "acc_by_round": self.o._acc,
                "loss_by_round": self.o._loss,
                "wall_time_sec": time.time() - self.o._t0
            }, f)

class KerasCNN(KerasTaskRunner):
    """A basic convolutional neural network model."""

    def __init__(self, **kwargs):
        """
        Initialize.

        Args:
            **kwargs: Additional parameters to pass to the function
        """
        super().__init__(**kwargs)

        #set self.lr
        self.lr = float(kwargs.get("lr", 1e-3))
        self.batch_size = int(kwargs.get("batch", 64))

        
        self.model = self.build_model(
            self.data_loader.get_feature_shape(),
            self.data_loader.get_num_classes(),
            **kwargs
        )

           # --- metrics buffers ---
        self._acc, self._loss = [], []
        self._t0 = time.time()

        # register callbacks for per-round metrics
        self._cb = tf.keras.callbacks.CSVLogger(
            os.path.join(os.environ.get("OUTDIR", "artifacts"), "history.csv"),
            append=False
        )

        #records and saves experiment metrics
        self._metrics_cb = _MetricsCB(self)
        #ensure call-backs used during fitting
        self.fit_kwargs = {
        "batch_size": self.batch_size,
        "callbacks": [self._metrics_cb, self._cb],
        }

        self.initialize_tensorkeys_for_functions()

        self.model.summary(print_fn=logger.info)

    def build_model(self,
                    input_shape,
                    num_classes,
                    conv_kernel_size=(4, 4),
                    conv_strides=(2, 2),
                    conv1_channels_out=16,
                    conv2_channels_out=32,
                    final_dense_inputsize=100,
                    **kwargs):
        """
        Define the model architecture.

        Args:
            input_shape (numpy.ndarray): The shape of the data
            num_classes (int): The number of classes of the dataset

        Returns:
            keras.models.Sequential: The model defined in Keras

        """
        model = Sequential()

        model.add(Conv2D(conv1_channels_out,
                         kernel_size=conv_kernel_size,
                         strides=conv_strides,
                         activation='relu',
                         input_shape=input_shape))

        model.add(Conv2D(conv2_channels_out,
                         kernel_size=conv_kernel_size,
                         strides=conv_strides,
                         activation='relu'))

        model.add(Flatten())

        model.add(Dense(final_dense_inputsize, activation='relu'))

        model.add(Dense(num_classes, activation='softmax'))

        model.compile(loss="categorical_crossentropy",
                      optimizer=Adam(learning_rate=self.lr),
                      metrics=["accuracy"])

        return model



if __name__ == "__main__":
    import tensorflow as tf
    import os, json, time

    # --- minimal data_loader to satisfy KerasTaskRunner ---
    class SimpleMNISTLoader:
        def get_feature_shape(self):  # H, W, C
            return [28, 28, 1]
        def get_num_classes(self):
            return 10

    # init model with the simple loader
    model = KerasCNN(data_loader=SimpleMNISTLoader())

    # load MNIST (centralized) for a quick smoke test
    (x_train, y_train), (x_val, y_val) = tf.keras.datasets.mnist.load_data()
    x_train = (x_train.astype("float32") / 255.0)[..., tf.newaxis]
    x_val   = (x_val.astype("float32") / 255.0)[..., tf.newaxis]
    y_train = tf.keras.utils.to_categorical(y_train, 10)
    y_val   = tf.keras.utils.to_categorical(y_val, 10)

    # ensure OUTDIR exists (used by your metrics callback)
    outdir = os.environ.get("OUTDIR", "artifacts/run1")
    os.makedirs(outdir, exist_ok=True)

    print("Starting training...")
    model.model.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        batch_size=model.batch_size,
        epochs=20,
        callbacks=[model._metrics_cb, model._cb],
        verbose=1,
    )
    print(f"Training complete. Metrics saved to {outdir}/metrics_raw.json")
